{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning Models for Weather Regulation Prediction\n",
    "\n",
    "This notebook demonstrates the advanced deep learning capabilities of the Weather Regulation Prediction System, including:\n",
    "\n",
    "1. **LSTM Networks** - For sequential weather pattern analysis\n",
    "2. **Transformer Models** - State-of-the-art attention-based architectures\n",
    "3. **CNN Models** - For spatial weather pattern recognition\n",
    "4. **Attention-LSTM** - Combining LSTM with attention mechanisms\n",
    "5. **Autoencoder** - For unsupervised feature learning\n",
    "6. **Ensemble Methods** - Combining multiple deep learning models\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Ensure you have TensorFlow installed:\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check TensorFlow availability\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. Some models will be skipped.\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## 1. Working with Balanced Dataset for Deep Learning\n\nDeep learning models, while powerful, are particularly sensitive to class imbalance. When regulations occur less than 10% of the time (typical in real aviation data), deep learning models often learn to simply predict \"no regulation\" most of the time, failing to capture the complex patterns that lead to actual regulations.\n\n### Benefits of Balanced Datasets for Deep Learning:\n\n1. **Better Feature Learning**: Neural networks can learn meaningful representations of both classes\n2. **Improved Gradient Flow**: Equal class representation helps gradients flow properly during backpropagation\n3. **Enhanced Pattern Recognition**: Models learn to recognize subtle patterns that distinguish regulation events\n4. **Reduced Bias**: Prevents models from being overly conservative in predictions\n5. **Better Calibration**: Prediction probabilities are more reliable and meaningful\n\nLet's load the balanced dataset specifically prepared for this advanced analysis.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Check TensorFlow availability\ntry:\n    import tensorflow as tf\n    print(f\"TensorFlow version: {tf.__version__}\")\n    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n    TENSORFLOW_AVAILABLE = True\nexcept ImportError:\n    print(\"TensorFlow not available. Some models will be skipped.\")\n    TENSORFLOW_AVAILABLE = False\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\nif TENSORFLOW_AVAILABLE:\n    tf.random.set_seed(42)\n\n# Load balanced dataset for deep learning\nimport os\n\nbalanced_data_path = '../data/balanced_weather_data.csv'\n\nif os.path.exists(balanced_data_path):\n    print(\"\\nüéØ Loading balanced dataset for deep learning...\")\n    balanced_data = pd.read_csv(balanced_data_path)\n    \n    # Convert timestamp to datetime\n    balanced_data['timestamp'] = pd.to_datetime(balanced_data['timestamp'])\n    \n    print(f\"‚úÖ Balanced dataset loaded successfully!\")\n    print(f\"   ‚Ä¢ Dataset shape: {balanced_data.shape}\")\n    print(f\"   ‚Ä¢ Regulation distribution: {balanced_data['has_regulation'].value_counts().to_dict()}\")\n    print(f\"   ‚Ä¢ Regulation rate: {balanced_data['has_regulation'].mean():.1%}\")\n    print(f\"   ‚Ä¢ Perfect balance for deep learning! üöÄ\")\n    \n    use_balanced = True\n    weather_data = balanced_data\nelse:\n    print(\"‚ö†Ô∏è  Balanced dataset not found. Generating synthetic data for demonstration...\")\n    use_balanced = False\n\nprint(\"\\nSetup complete!\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "<cell_type>markdown</cell_type>## 2. Data Preparation for Deep Learning (Alternative)\n\nIf the balanced dataset is not available, we'll generate more complex synthetic data. However, using the balanced dataset is strongly recommended for production deep learning models."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Generate more complex time series data for deep learning (only if balanced dataset not available)\nif not use_balanced:\n    def generate_complex_weather_sequences(n_samples=2000, sequence_length=24):\n        \"\"\"Generate complex weather time series with multiple patterns\"\"\"\n        \n        # Time features\n        timestamps = pd.date_range('2023-01-01', periods=n_samples, freq='1H')\n        hour_of_day = timestamps.hour\n        day_of_year = timestamps.dayofyear\n        \n        # Multiple weather patterns\n        # 1. Diurnal temperature cycle\n        temp_diurnal = 15 + 10 * np.sin(2 * np.pi * hour_of_day / 24)\n        \n        # 2. Seasonal temperature cycle\n        temp_seasonal = 8 * np.sin(2 * np.pi * day_of_year / 365)\n        \n        # 3. Weather system movements (3-day cycles)\n        temp_systems = 5 * np.sin(2 * np.pi * np.arange(n_samples) / (3*24))\n        \n        # Combine temperature patterns with noise\n        temperature = temp_diurnal + temp_seasonal + temp_systems + np.random.normal(0, 2, n_samples)\n        \n        # Pressure anticorrelated with temperature systems\n        pressure = 1013 - 0.5 * temp_systems + np.random.normal(0, 8, n_samples)\n        \n        # Wind patterns\n        wind_base = 8 + 5 * np.sin(2 * np.pi * hour_of_day / 24 + np.pi/3)\n        wind_speed = np.abs(wind_base + 3 * np.sin(2 * np.pi * np.arange(n_samples) / (2*24)) + \n                            np.random.normal(0, 2, n_samples))\n        \n        wind_direction = (180 + 60 * np.sin(2 * np.pi * np.arange(n_samples) / (4*24)) + \n                         np.random.normal(0, 30, n_samples)) % 360\n        \n        # Visibility affected by humidity and weather conditions\n        humidity = 50 + 30 * np.sin(2 * np.pi * hour_of_day / 24 + np.pi) + np.random.normal(0, 10, n_samples)\n        humidity = np.clip(humidity, 10, 100)\n        \n        # Visibility decreases with high humidity and adverse weather\n        visibility_base = 15000 - 100 * humidity\n        visibility = np.clip(visibility_base + np.random.normal(0, 2000, n_samples), 1000, 20000)\n        \n        # Cloud cover patterns\n        cloud_cover = np.clip(humidity / 2 + np.random.normal(0, 20, n_samples), 0, 100)\n        \n        # Create DataFrame\n        data = pd.DataFrame({\n            'timestamp': timestamps,\n            'temperature': temperature,\n            'pressure': pressure,\n            'wind_speed': wind_speed,\n            'wind_direction': wind_direction,\n            'visibility': visibility,\n            'humidity': humidity,\n            'cloud_cover': cloud_cover,\n            'hour': hour_of_day,\n            'day_of_year': day_of_year\n        })\n        \n        return data\n\n    # Generate data\n    weather_data = generate_complex_weather_sequences(n_samples=2000)\n    print(f\"Generated weather data shape: {weather_data.shape}\")\n    print(\"\\nWeather data sample:\")\n    print(weather_data.head())\nelse:\n    print(\"‚úÖ Using balanced dataset - skipping synthetic data generation\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequence Data Preparation\n",
    "\n",
    "Deep learning models often work with sequences. Let's prepare our data for sequential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, sequence_length=24, target_col='has_regulation'):\n",
    "    \"\"\"Create sequences for deep learning models\"\"\"\n",
    "    \n",
    "    # Select features for sequences\n",
    "    feature_cols = ['temperature', 'pressure', 'wind_speed', 'wind_direction', \n",
    "                   'visibility', 'humidity', 'cloud_cover', 'weather_severity']\n",
    "    \n",
    "    X_sequences = []\n",
    "    y_sequences = []\n",
    "    \n",
    "    for i in range(sequence_length, len(data)):\n",
    "        # Get sequence of features\n",
    "        sequence = data[feature_cols].iloc[i-sequence_length:i].values\n",
    "        target = data[target_col].iloc[i]\n",
    "        \n",
    "        X_sequences.append(sequence)\n",
    "        y_sequences.append(target)\n",
    "    \n",
    "    return np.array(X_sequences), np.array(y_sequences), feature_cols\n",
    "\n",
    "# Create sequences\n",
    "sequence_length = 24  # 24 hours of history\n",
    "X_sequences, y_sequences, feature_names = create_sequences(weather_data, sequence_length)\n",
    "\n",
    "print(f\"Sequence data shape: {X_sequences.shape}\")\n",
    "print(f\"Target shape: {y_sequences.shape}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Regulation rate in sequences: {y_sequences.mean():.1%}\")\n",
    "\n",
    "# Split data for deep learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split sequences\n",
    "X_train_seq, X_temp_seq, y_train_seq, y_temp_seq = train_test_split(\n",
    "    X_sequences, y_sequences, test_size=0.4, random_state=42, stratify=y_sequences\n",
    ")\n",
    "X_val_seq, X_test_seq, y_val_seq, y_test_seq = train_test_split(\n",
    "    X_temp_seq, y_temp_seq, test_size=0.5, random_state=42, stratify=y_temp_seq\n",
    ")\n",
    "\n",
    "# Scale the sequences\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape for scaling\n",
    "X_train_reshaped = X_train_seq.reshape(-1, X_train_seq.shape[-1])\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "X_train_seq_scaled = X_train_scaled.reshape(X_train_seq.shape)\n",
    "\n",
    "X_val_reshaped = X_val_seq.reshape(-1, X_val_seq.shape[-1])\n",
    "X_val_scaled = scaler.transform(X_val_reshaped)\n",
    "X_val_seq_scaled = X_val_scaled.reshape(X_val_seq.shape)\n",
    "\n",
    "X_test_reshaped = X_test_seq.reshape(-1, X_test_seq.shape[-1])\n",
    "X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "X_test_seq_scaled = X_test_scaled.reshape(X_test_seq.shape)\n",
    "\n",
    "print(f\"\\nTraining sequences: {X_train_seq_scaled.shape}\")\n",
    "print(f\"Validation sequences: {X_val_seq_scaled.shape}\")\n",
    "print(f\"Test sequences: {X_test_seq_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def create_sequences(data, sequence_length=24, target_col='has_regulation'):\n    \"\"\"Create sequences for deep learning models\"\"\"\n    \n    # Select features for sequences based on available columns\n    if use_balanced:\n        # For balanced dataset, select appropriate numerical features\n        feature_cols = [col for col in data.columns \n                       if col not in ['timestamp', 'airport', 'has_regulation', 'weather_code', 'flight_category', 'regulation_type'] \n                       and data[col].dtype in ['float64', 'int64']]\n        # Ensure we have key weather features\n        key_features = ['temperature', 'pressure', 'wind_speed', 'wind_direction', 'visibility', 'humidity']\n        feature_cols = [col for col in key_features if col in feature_cols] + \\\n                      [col for col in feature_cols if col not in key_features][:8]  # Limit to avoid too many features\n        feature_cols = feature_cols[:8]  # Keep reasonable number of features\n    else:\n        # For synthetic data\n        feature_cols = ['temperature', 'pressure', 'wind_speed', 'wind_direction', \n                       'visibility', 'humidity', 'cloud_cover', 'weather_severity']\n    \n    print(f\"Using features for sequences: {feature_cols}\")\n    \n    X_sequences = []\n    y_sequences = []\n    \n    for i in range(sequence_length, len(data)):\n        # Get sequence of features\n        sequence = data[feature_cols].iloc[i-sequence_length:i].values\n        target = data[target_col].iloc[i]\n        \n        X_sequences.append(sequence)\n        y_sequences.append(target)\n    \n    return np.array(X_sequences), np.array(y_sequences), feature_cols\n\n# Create sequences\nsequence_length = 24  # 24 hours of history (or 24 time steps for balanced data)\nX_sequences, y_sequences, feature_names = create_sequences(weather_data, sequence_length)\n\nprint(f\"Sequence data shape: {X_sequences.shape}\")\nprint(f\"Target shape: {y_sequences.shape}\")\nprint(f\"Features: {feature_names}\")\nprint(f\"Regulation rate in sequences: {y_sequences.mean():.1%}\")\n\n# Display class balance\nif use_balanced:\n    print(f\"‚úÖ Class distribution in sequences:\")\n    unique, counts = np.unique(y_sequences, return_counts=True)\n    for cls, count in zip(unique, counts):\n        print(f\"   Class {cls}: {count} samples ({count/len(y_sequences)*100:.1f}%)\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    from models.lstm import LSTMModel\n",
    "    from config import LSTMConfig\n",
    "    from training.trainer import Trainer\n",
    "    \n",
    "    # Configure LSTM model\n",
    "    lstm_config = LSTMConfig(\n",
    "        units=64,\n",
    "        dropout=0.3,\n",
    "        recurrent_dropout=0.3,\n",
    "        bidirectional=True,\n",
    "        batch_size=32,\n",
    "        epochs=50,\n",
    "        sequence_length=sequence_length,\n",
    "        learning_rate=0.001,\n",
    "        early_stopping_patience=10\n",
    "    )\n",
    "    \n",
    "    print(\"Training LSTM model...\")\n",
    "    print(f\"Configuration: {lstm_config.__dict__}\")\n",
    "    \n",
    "    # Create and train model\n",
    "    lstm_model = LSTMModel(lstm_config)\n",
    "    trainer = Trainer()\n",
    "    \n",
    "    lstm_results = trainer.train_model(\n",
    "        model=lstm_model,\n",
    "        X_train=X_train_seq_scaled,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_seq_scaled,\n",
    "        y_val=y_val_seq,\n",
    "        model_name=\"lstm_weather\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nLSTM Training Results:\")\n",
    "    print(f\"- Accuracy: {lstm_results['accuracy']:.3f}\")\n",
    "    print(f\"- Precision: {lstm_results['precision']:.3f}\")\n",
    "    print(f\"- Recall: {lstm_results['recall']:.3f}\")\n",
    "    print(f\"- F1 Score: {lstm_results['f1_score']:.3f}\")\n",
    "    print(f\"- Training Time: {lstm_results['training_time']:.2f}s\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available, skipping LSTM training\")\n",
    "    lstm_model = None\n",
    "    lstm_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize LSTM training history if available\n",
    "if TENSORFLOW_AVAILABLE and lstm_model is not None:\n",
    "    # Get training history\n",
    "    if hasattr(lstm_model, 'training_history') and lstm_model.training_history:\n",
    "        history = lstm_model.training_history\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss curves\n",
    "        if 'loss' in history:\n",
    "            axes[0].plot(history['loss'], label='Training Loss')\n",
    "            if 'val_loss' in history:\n",
    "                axes[0].plot(history['val_loss'], label='Validation Loss')\n",
    "            axes[0].set_title('LSTM Training Loss')\n",
    "            axes[0].set_xlabel('Epoch')\n",
    "            axes[0].set_ylabel('Loss')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Accuracy curves\n",
    "        if 'accuracy' in history:\n",
    "            axes[1].plot(history['accuracy'], label='Training Accuracy')\n",
    "            if 'val_accuracy' in history:\n",
    "                axes[1].plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "            axes[1].set_title('LSTM Training Accuracy')\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('Accuracy')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Training history not available\")\n",
    "        \n",
    "    # Evaluate on test set\n",
    "    lstm_test_metrics = lstm_model.evaluate(X_test_seq_scaled, y_test_seq)\n",
    "    print(f\"\\nLSTM Test Results:\")\n",
    "    print(f\"- Accuracy: {lstm_test_metrics.accuracy:.3f}\")\n",
    "    print(f\"- Precision: {lstm_test_metrics.precision:.3f}\")\n",
    "    print(f\"- Recall: {lstm_test_metrics.recall:.3f}\")\n",
    "    print(f\"- F1 Score: {lstm_test_metrics.f1_score:.3f}\")\n",
    "    print(f\"- AUC-ROC: {lstm_test_metrics.auc_roc:.3f}\")\n",
    "else:\n",
    "    print(\"LSTM model not available for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformer Model\n",
    "\n",
    "Now let's train a Transformer model for weather sequence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    from models.transformer import TransformerModel\n",
    "    from config import TransformerConfig\n",
    "    \n",
    "    # Configure Transformer model\n",
    "    transformer_config = TransformerConfig(\n",
    "        d_model=128,\n",
    "        num_heads=8,\n",
    "        num_layers=4,\n",
    "        dropout=0.1,\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=32,\n",
    "        epochs=30,  # Fewer epochs for demo\n",
    "        learning_rate=0.0001,\n",
    "        warmup_steps=1000\n",
    "    )\n",
    "    \n",
    "    print(\"Training Transformer model...\")\n",
    "    print(f\"Configuration: {transformer_config.__dict__}\")\n",
    "    \n",
    "    # Create and train model\n",
    "    transformer_model = TransformerModel(transformer_config)\n",
    "    \n",
    "    transformer_results = trainer.train_model(\n",
    "        model=transformer_model,\n",
    "        X_train=X_train_seq_scaled,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_seq_scaled,\n",
    "        y_val=y_val_seq,\n",
    "        model_name=\"transformer_weather\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTransformer Training Results:\")\n",
    "    print(f\"- Accuracy: {transformer_results['accuracy']:.3f}\")\n",
    "    print(f\"- Precision: {transformer_results['precision']:.3f}\")\n",
    "    print(f\"- Recall: {transformer_results['recall']:.3f}\")\n",
    "    print(f\"- F1 Score: {transformer_results['f1_score']:.3f}\")\n",
    "    print(f\"- Training Time: {transformer_results['training_time']:.2f}s\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    transformer_test_metrics = transformer_model.evaluate(X_test_seq_scaled, y_test_seq)\n",
    "    print(f\"\\nTransformer Test Results:\")\n",
    "    print(f\"- Accuracy: {transformer_test_metrics.accuracy:.3f}\")\n",
    "    print(f\"- Precision: {transformer_test_metrics.precision:.3f}\")\n",
    "    print(f\"- Recall: {transformer_test_metrics.recall:.3f}\")\n",
    "    print(f\"- F1 Score: {transformer_test_metrics.f1_score:.3f}\")\n",
    "    print(f\"- AUC-ROC: {transformer_test_metrics.auc_roc:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available, skipping Transformer training\")\n",
    "    transformer_model = None\n",
    "    transformer_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attention-LSTM Model\n",
    "\n",
    "Let's try an LSTM with attention mechanism for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    from models.attention_lstm import AttentionLSTMModel\n",
    "    from config import LSTMConfig  # Reuse LSTM config for attention model\n",
    "    \n",
    "    # Configure Attention-LSTM model\n",
    "    attention_lstm_config = LSTMConfig(\n",
    "        units=64,\n",
    "        dropout=0.3,\n",
    "        recurrent_dropout=0.3,\n",
    "        batch_size=32,\n",
    "        epochs=40,\n",
    "        sequence_length=sequence_length,\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    print(\"Training Attention-LSTM model...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    attention_lstm_model = AttentionLSTMModel(attention_lstm_config)\n",
    "    \n",
    "    attention_lstm_results = trainer.train_model(\n",
    "        model=attention_lstm_model,\n",
    "        X_train=X_train_seq_scaled,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_seq_scaled,\n",
    "        y_val=y_val_seq,\n",
    "        model_name=\"attention_lstm_weather\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAttention-LSTM Training Results:\")\n",
    "    print(f\"- Accuracy: {attention_lstm_results['accuracy']:.3f}\")\n",
    "    print(f\"- Precision: {attention_lstm_results['precision']:.3f}\")\n",
    "    print(f\"- Recall: {attention_lstm_results['recall']:.3f}\")\n",
    "    print(f\"- F1 Score: {attention_lstm_results['f1_score']:.3f}\")\n",
    "    print(f\"- Training Time: {attention_lstm_results['training_time']:.2f}s\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    attention_lstm_test_metrics = attention_lstm_model.evaluate(X_test_seq_scaled, y_test_seq)\n",
    "    print(f\"\\nAttention-LSTM Test Results:\")\n",
    "    print(f\"- Accuracy: {attention_lstm_test_metrics.accuracy:.3f}\")\n",
    "    print(f\"- Precision: {attention_lstm_test_metrics.precision:.3f}\")\n",
    "    print(f\"- Recall: {attention_lstm_test_metrics.recall:.3f}\")\n",
    "    print(f\"- F1 Score: {attention_lstm_test_metrics.f1_score:.3f}\")\n",
    "    print(f\"- AUC-ROC: {attention_lstm_test_metrics.auc_roc:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available, skipping Attention-LSTM training\")\n",
    "    attention_lstm_model = None\n",
    "    attention_lstm_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CNN Model for Spatial Patterns\n",
    "\n",
    "CNNs can capture spatial patterns in weather data when reshaped appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    from models.cnn import CNNModel\n",
    "    from config import CNNConfig\n",
    "    \n",
    "    # Reshape sequence data for CNN (treat sequence as 2D image)\n",
    "    # For CNN: (samples, height, width, channels)\n",
    "    # We'll reshape to treat time as height and features as width\n",
    "    def reshape_for_cnn(X_seq):\n",
    "        # X_seq shape: (samples, time_steps, features)\n",
    "        # Reshape to: (samples, time_steps, features, 1)\n",
    "        return np.expand_dims(X_seq, axis=-1)\n",
    "    \n",
    "    X_train_cnn = reshape_for_cnn(X_train_seq_scaled)\n",
    "    X_val_cnn = reshape_for_cnn(X_val_seq_scaled)\n",
    "    X_test_cnn = reshape_for_cnn(X_test_seq_scaled)\n",
    "    \n",
    "    print(f\"CNN input shape: {X_train_cnn.shape}\")\n",
    "    \n",
    "    # Configure CNN model\n",
    "    cnn_config = CNNConfig(\n",
    "        filters=[32, 64, 128],\n",
    "        kernel_sizes=[3, 3, 3],\n",
    "        pool_sizes=[2, 2, 2],\n",
    "        dropout=0.3,\n",
    "        batch_size=32,\n",
    "        epochs=30,\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    print(\"Training CNN model...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    cnn_model = CNNModel(cnn_config)\n",
    "    \n",
    "    cnn_results = trainer.train_model(\n",
    "        model=cnn_model,\n",
    "        X_train=X_train_cnn,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_cnn,\n",
    "        y_val=y_val_seq,\n",
    "        model_name=\"cnn_weather\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCNN Training Results:\")\n",
    "    print(f\"- Accuracy: {cnn_results['accuracy']:.3f}\")\n",
    "    print(f\"- Precision: {cnn_results['precision']:.3f}\")\n",
    "    print(f\"- Recall: {cnn_results['recall']:.3f}\")\n",
    "    print(f\"- F1 Score: {cnn_results['f1_score']:.3f}\")\n",
    "    print(f\"- Training Time: {cnn_results['training_time']:.2f}s\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    cnn_test_metrics = cnn_model.evaluate(X_test_cnn, y_test_seq)\n",
    "    print(f\"\\nCNN Test Results:\")\n",
    "    print(f\"- Accuracy: {cnn_test_metrics.accuracy:.3f}\")\n",
    "    print(f\"- Precision: {cnn_test_metrics.precision:.3f}\")\n",
    "    print(f\"- Recall: {cnn_test_metrics.recall:.3f}\")\n",
    "    print(f\"- F1 Score: {cnn_test_metrics.f1_score:.3f}\")\n",
    "    print(f\"- AUC-ROC: {cnn_test_metrics.auc_roc:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available, skipping CNN training\")\n",
    "    cnn_model = None\n",
    "    cnn_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Autoencoder for Feature Learning\n",
    "\n",
    "Let's use an autoencoder to learn compressed representations of weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    from models.autoencoder import AutoencoderModel\n",
    "    from config import AutoencoderConfig\n",
    "    \n",
    "    # Flatten sequences for autoencoder\n",
    "    X_train_flat = X_train_seq_scaled.reshape(X_train_seq_scaled.shape[0], -1)\n",
    "    X_val_flat = X_val_seq_scaled.reshape(X_val_seq_scaled.shape[0], -1)\n",
    "    X_test_flat = X_test_seq_scaled.reshape(X_test_seq_scaled.shape[0], -1)\n",
    "    \n",
    "    print(f\"Flattened input shape: {X_train_flat.shape}\")\n",
    "    \n",
    "    # Configure Autoencoder\n",
    "    autoencoder_config = AutoencoderConfig(\n",
    "        encoding_dims=[128, 64, 32],  # Compress to 32 dimensions\n",
    "        dropout=0.2,\n",
    "        batch_size=32,\n",
    "        pretrain_epochs=20,  # Unsupervised pretraining\n",
    "        epochs=30,  # Supervised fine-tuning\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    print(\"Training Autoencoder model...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    autoencoder_model = AutoencoderModel(autoencoder_config)\n",
    "    \n",
    "    autoencoder_results = trainer.train_model(\n",
    "        model=autoencoder_model,\n",
    "        X_train=X_train_flat,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_flat,\n",
    "        y_val=y_val_seq,\n",
    "        model_name=\"autoencoder_weather\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAutoencoder Training Results:\")\n",
    "    print(f\"- Accuracy: {autoencoder_results['accuracy']:.3f}\")\n",
    "    print(f\"- Precision: {autoencoder_results['precision']:.3f}\")\n",
    "    print(f\"- Recall: {autoencoder_results['recall']:.3f}\")\n",
    "    print(f\"- F1 Score: {autoencoder_results['f1_score']:.3f}\")\n",
    "    print(f\"- Training Time: {autoencoder_results['training_time']:.2f}s\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    autoencoder_test_metrics = autoencoder_model.evaluate(X_test_flat, y_test_seq)\n",
    "    print(f\"\\nAutoencoder Test Results:\")\n",
    "    print(f\"- Accuracy: {autoencoder_test_metrics.accuracy:.3f}\")\n",
    "    print(f\"- Precision: {autoencoder_test_metrics.precision:.3f}\")\n",
    "    print(f\"- Recall: {autoencoder_test_metrics.recall:.3f}\")\n",
    "    print(f\"- F1 Score: {autoencoder_test_metrics.f1_score:.3f}\")\n",
    "    print(f\"- AUC-ROC: {autoencoder_test_metrics.auc_roc:.3f}\")\n",
    "    \n",
    "    # Extract learned features\n",
    "    encoded_features = autoencoder_model.extract_features(X_test_flat)\n",
    "    print(f\"\\nLearned feature dimensions: {encoded_features.shape[1]}\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available, skipping Autoencoder training\")\n",
    "    autoencoder_model = None\n",
    "    autoencoder_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ensemble of Deep Learning Models\n",
    "\n",
    "Let's create an ensemble combining our best deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    from models.ensemble import EnsembleModel\n",
    "    from config import EnsembleConfig\n",
    "    \n",
    "    # Create ensemble configuration\n",
    "    ensemble_config = EnsembleConfig(\n",
    "        base_models=[\n",
    "            {'type': 'lstm', 'units': 64, 'dropout': 0.3, 'epochs': 20},\n",
    "            {'type': 'random_forest', 'n_estimators': 100, 'max_depth': 10}\n",
    "        ],\n",
    "        ensemble_method='voting',\n",
    "        voting_type='soft'\n",
    "    )\n",
    "    \n",
    "    print(\"Training Deep Learning Ensemble...\")\n",
    "    \n",
    "    # For ensemble, we'll use flattened data (can handle both types)\n",
    "    ensemble_model = EnsembleModel(ensemble_config)\n",
    "    \n",
    "    ensemble_results = trainer.train_model(\n",
    "        model=ensemble_model,\n",
    "        X_train=X_train_flat,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_flat,\n",
    "        y_val=y_val_seq,\n",
    "        model_name=\"dl_ensemble_weather\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEnsemble Training Results:\")\n",
    "    print(f\"- Accuracy: {ensemble_results['accuracy']:.3f}\")\n",
    "    print(f\"- Precision: {ensemble_results['precision']:.3f}\")\n",
    "    print(f\"- Recall: {ensemble_results['recall']:.3f}\")\n",
    "    print(f\"- F1 Score: {ensemble_results['f1_score']:.3f}\")\n",
    "    print(f\"- Training Time: {ensemble_results['training_time']:.2f}s\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    ensemble_test_metrics = ensemble_model.evaluate(X_test_flat, y_test_seq)\n",
    "    print(f\"\\nEnsemble Test Results:\")\n",
    "    print(f\"- Accuracy: {ensemble_test_metrics.accuracy:.3f}\")\n",
    "    print(f\"- Precision: {ensemble_test_metrics.precision:.3f}\")\n",
    "    print(f\"- Recall: {ensemble_test_metrics.recall:.3f}\")\n",
    "    print(f\"- F1 Score: {ensemble_test_metrics.f1_score:.3f}\")\n",
    "    print(f\"- AUC-ROC: {ensemble_test_metrics.auc_roc:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available, skipping ensemble training\")\n",
    "    ensemble_model = None\n",
    "    ensemble_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison and Analysis\n",
    "\n",
    "Let's compare all our deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results for comparison\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    model_results = []\n",
    "    \n",
    "    # Add each model if it was trained successfully\n",
    "    if lstm_model is not None:\n",
    "        model_results.append({\n",
    "            'Model': 'LSTM',\n",
    "            'Accuracy': lstm_test_metrics.accuracy,\n",
    "            'Precision': lstm_test_metrics.precision,\n",
    "            'Recall': lstm_test_metrics.recall,\n",
    "            'F1 Score': lstm_test_metrics.f1_score,\n",
    "            'AUC-ROC': lstm_test_metrics.auc_roc,\n",
    "            'Training Time (s)': lstm_results['training_time']\n",
    "        })\n",
    "    \n",
    "    if transformer_model is not None:\n",
    "        model_results.append({\n",
    "            'Model': 'Transformer',\n",
    "            'Accuracy': transformer_test_metrics.accuracy,\n",
    "            'Precision': transformer_test_metrics.precision,\n",
    "            'Recall': transformer_test_metrics.recall,\n",
    "            'F1 Score': transformer_test_metrics.f1_score,\n",
    "            'AUC-ROC': transformer_test_metrics.auc_roc,\n",
    "            'Training Time (s)': transformer_results['training_time']\n",
    "        })\n",
    "    \n",
    "    if attention_lstm_model is not None:\n",
    "        model_results.append({\n",
    "            'Model': 'Attention-LSTM',\n",
    "            'Accuracy': attention_lstm_test_metrics.accuracy,\n",
    "            'Precision': attention_lstm_test_metrics.precision,\n",
    "            'Recall': attention_lstm_test_metrics.recall,\n",
    "            'F1 Score': attention_lstm_test_metrics.f1_score,\n",
    "            'AUC-ROC': attention_lstm_test_metrics.auc_roc,\n",
    "            'Training Time (s)': attention_lstm_results['training_time']\n",
    "        })\n",
    "    \n",
    "    if cnn_model is not None:\n",
    "        model_results.append({\n",
    "            'Model': 'CNN',\n",
    "            'Accuracy': cnn_test_metrics.accuracy,\n",
    "            'Precision': cnn_test_metrics.precision,\n",
    "            'Recall': cnn_test_metrics.recall,\n",
    "            'F1 Score': cnn_test_metrics.f1_score,\n",
    "            'AUC-ROC': cnn_test_metrics.auc_roc,\n",
    "            'Training Time (s)': cnn_results['training_time']\n",
    "        })\n",
    "    \n",
    "    if autoencoder_model is not None:\n",
    "        model_results.append({\n",
    "            'Model': 'Autoencoder',\n",
    "            'Accuracy': autoencoder_test_metrics.accuracy,\n",
    "            'Precision': autoencoder_test_metrics.precision,\n",
    "            'Recall': autoencoder_test_metrics.recall,\n",
    "            'F1 Score': autoencoder_test_metrics.f1_score,\n",
    "            'AUC-ROC': autoencoder_test_metrics.auc_roc,\n",
    "            'Training Time (s)': autoencoder_results['training_time']\n",
    "        })\n",
    "    \n",
    "    if ensemble_model is not None:\n",
    "        model_results.append({\n",
    "            'Model': 'Ensemble',\n",
    "            'Accuracy': ensemble_test_metrics.accuracy,\n",
    "            'Precision': ensemble_test_metrics.precision,\n",
    "            'Recall': ensemble_test_metrics.recall,\n",
    "            'F1 Score': ensemble_test_metrics.f1_score,\n",
    "            'AUC-ROC': ensemble_test_metrics.auc_roc,\n",
    "            'Training Time (s)': ensemble_results['training_time']\n",
    "        })\n",
    "    \n",
    "    if model_results:\n",
    "        comparison_df = pd.DataFrame(model_results)\n",
    "        comparison_df = comparison_df.round(3)\n",
    "        \n",
    "        print(\"Deep Learning Model Comparison:\")\n",
    "        print(\"=\" * 100)\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Find best models\n",
    "        print(\"\\nBest Models by Metric:\")\n",
    "        print(\"=\" * 50)\n",
    "        for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC']:\n",
    "            best_idx = comparison_df[metric].idxmax()\n",
    "            best_model = comparison_df.loc[best_idx, 'Model']\n",
    "            best_value = comparison_df.loc[best_idx, metric]\n",
    "            print(f\"{metric:>12}: {best_model} ({best_value:.3f})\")\n",
    "    else:\n",
    "        print(\"No models were successfully trained for comparison.\")\n",
    "\n",
    "else:\n",
    "    print(\"TensorFlow not available, no deep learning models to compare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "if TENSORFLOW_AVAILABLE and 'comparison_df' in locals() and len(comparison_df) > 0:\n",
    "    # Performance comparison bar chart\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Deep Learning Model Performance Comparison', fontsize=16)\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    axes[0, 0].bar(comparison_df['Model'], comparison_df['Accuracy'], color='skyblue')\n",
    "    axes[0, 0].set_title('Accuracy Comparison')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # F1 Score comparison\n",
    "    axes[0, 1].bar(comparison_df['Model'], comparison_df['F1 Score'], color='lightgreen')\n",
    "    axes[0, 1].set_title('F1 Score Comparison')\n",
    "    axes[0, 1].set_ylabel('F1 Score')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # AUC-ROC comparison\n",
    "    axes[1, 0].bar(comparison_df['Model'], comparison_df['AUC-ROC'], color='coral')\n",
    "    axes[1, 0].set_title('AUC-ROC Comparison')\n",
    "    axes[1, 0].set_ylabel('AUC-ROC')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # Training time comparison\n",
    "    axes[1, 1].bar(comparison_df['Model'], comparison_df['Training Time (s)'], color='gold')\n",
    "    axes[1, 1].set_title('Training Time Comparison')\n",
    "    axes[1, 1].set_ylabel('Training Time (seconds)')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Radar chart for multi-metric comparison\n",
    "    import math\n",
    "    \n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC']\n",
    "    angles = [n / float(len(metrics)) * 2 * math.pi for n in range(len(metrics))]\n",
    "    angles += angles[:1]  # Complete the circle\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']\n",
    "    \n",
    "    for i, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "        if i < len(colors):\n",
    "            values = [row[metric] for metric in metrics]\n",
    "            values += values[:1]  # Complete the circle\n",
    "            \n",
    "            ax.plot(angles, values, 'o-', linewidth=2, label=row['Model'], color=colors[i])\n",
    "            ax.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Deep Learning Model Performance (Radar Chart)', size=16, y=1.1)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No comparison data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Interpretation and Analysis\n",
    "\n",
    "Let's analyze what our deep learning models have learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze predictions and patterns\n",
    "if TENSORFLOW_AVAILABLE and lstm_model is not None:\n",
    "    # Get predictions from the best model\n",
    "    lstm_predictions = lstm_model.predict(X_test_seq_scaled)\n",
    "    lstm_probabilities = lstm_model.predict_proba(X_test_seq_scaled)\n",
    "    \n",
    "    # Analyze prediction confidence\n",
    "    confidence_scores = np.max(lstm_probabilities, axis=1)\n",
    "    \n",
    "    # Create prediction analysis\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('LSTM Model Analysis', fontsize=16)\n",
    "    \n",
    "    # Prediction confidence distribution\n",
    "    axes[0, 0].hist(confidence_scores, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].set_title('Prediction Confidence Distribution')\n",
    "    axes[0, 0].set_xlabel('Confidence Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Confidence vs accuracy\n",
    "    correct_predictions = (lstm_predictions == y_test_seq)\n",
    "    axes[0, 1].scatter(confidence_scores[correct_predictions], \n",
    "                      np.ones(sum(correct_predictions)), \n",
    "                      alpha=0.6, label='Correct', s=10)\n",
    "    axes[0, 1].scatter(confidence_scores[~correct_predictions], \n",
    "                      np.zeros(sum(~correct_predictions)), \n",
    "                      alpha=0.6, label='Incorrect', s=10, color='red')\n",
    "    axes[0, 1].set_title('Confidence vs Correctness')\n",
    "    axes[0, 1].set_xlabel('Confidence Score')\n",
    "    axes[0, 1].set_ylabel('Correct (1) / Incorrect (0)')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Prediction probability distribution\n",
    "    reg_probs = lstm_probabilities[y_test_seq == 1][:, 1]  # Regulation probability for actual regulations\n",
    "    no_reg_probs = lstm_probabilities[y_test_seq == 0][:, 1]  # Regulation probability for no regulations\n",
    "    \n",
    "    axes[1, 0].hist(no_reg_probs, bins=30, alpha=0.7, label='No Regulation (True)', color='blue')\n",
    "    axes[1, 0].hist(reg_probs, bins=30, alpha=0.7, label='Regulation (True)', color='red')\n",
    "    axes[1, 0].set_title('Predicted Probability Distribution')\n",
    "    axes[1, 0].set_xlabel('Predicted Regulation Probability')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Feature importance proxy (using gradient approximation)\n",
    "    # For demonstration, we'll show which time steps are most important\n",
    "    sample_sequences = X_test_seq_scaled[:100]  # Use first 100 test samples\n",
    "    base_pred = lstm_model.predict_proba(sample_sequences)[:, 1]\n",
    "    \n",
    "    # Perturb each time step and measure impact\n",
    "    time_importance = []\n",
    "    for t in range(sequence_length):\n",
    "        perturbed_sequences = sample_sequences.copy()\n",
    "        perturbed_sequences[:, t, :] = 0  # Zero out time step t\n",
    "        perturbed_pred = lstm_model.predict_proba(perturbed_sequences)[:, 1]\n",
    "        importance = np.mean(np.abs(base_pred - perturbed_pred))\n",
    "        time_importance.append(importance)\n",
    "    \n",
    "    axes[1, 1].plot(range(sequence_length), time_importance, marker='o')\n",
    "    axes[1, 1].set_title('Time Step Importance (Hours Before)')\n",
    "    axes[1, 1].set_xlabel('Hours Before Current Time')\n",
    "    axes[1, 1].set_ylabel('Average Impact on Prediction')\n",
    "    axes[1, 1].invert_xaxis()  # Most recent time on the right\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print insights\n",
    "    print(\"Model Analysis Insights:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Average prediction confidence: {confidence_scores.mean():.3f}\")\n",
    "    print(f\"High confidence predictions (>0.9): {(confidence_scores > 0.9).mean():.1%}\")\n",
    "    print(f\"Low confidence predictions (<0.6): {(confidence_scores < 0.6).mean():.1%}\")\n",
    "    \n",
    "    most_important_time = np.argmax(time_importance)\n",
    "    print(f\"Most important time step: {sequence_length - most_important_time} hours before\")\n",
    "    print(f\"Recent hours (last 6) average importance: {np.mean(time_importance[-6:]):.4f}\")\n",
    "    print(f\"Earlier hours (first 6) average importance: {np.mean(time_importance[:6]):.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"LSTM model not available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Hyperparameter Tuning for Deep Learning\n",
    "\n",
    "Let's demonstrate advanced hyperparameter tuning for our best deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    from training.hyperparameter_tuning import BayesianOptimizationTuner\n",
    "    \n",
    "    # Define parameter space for LSTM tuning\n",
    "    param_space = {\n",
    "        'units': [32, 128],\n",
    "        'dropout': [0.1, 0.5],\n",
    "        'recurrent_dropout': [0.1, 0.5],\n",
    "        'learning_rate': [0.0001, 0.01],\n",
    "        'batch_size': [16, 64]\n",
    "    }\n",
    "    \n",
    "    print(\"Starting Bayesian optimization for LSTM...\")\n",
    "    print(f\"Parameter space: {param_space}\")\n",
    "    \n",
    "    # Create base model for tuning\n",
    "    base_config = LSTMConfig(epochs=15, sequence_length=sequence_length)  # Fewer epochs for speed\n",
    "    tuning_model = LSTMModel(base_config)\n",
    "    \n",
    "    # Perform Bayesian optimization\n",
    "    tuner = BayesianOptimizationTuner(n_trials=10)  # Limited trials for demo\n",
    "    \n",
    "    tuning_result = tuner.tune(\n",
    "        model=tuning_model,\n",
    "        param_space=param_space,\n",
    "        X_train=X_train_seq_scaled,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_seq_scaled,\n",
    "        y_val=y_val_seq\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBayesian Optimization Results:\")\n",
    "    print(f\"Best parameters: {tuning_result.best_params}\")\n",
    "    print(f\"Best validation score: {tuning_result.best_score:.3f}\")\n",
    "    print(f\"Number of trials: {len(tuning_result.all_results)}\")\n",
    "    \n",
    "    # Train optimized model\n",
    "    optimized_config = LSTMConfig(\n",
    "        **tuning_result.best_params,\n",
    "        epochs=30,\n",
    "        sequence_length=sequence_length\n",
    "    )\n",
    "    \n",
    "    optimized_lstm = LSTMModel(optimized_config)\n",
    "    \n",
    "    optimized_results = trainer.train_model(\n",
    "        model=optimized_lstm,\n",
    "        X_train=X_train_seq_scaled,\n",
    "        y_train=y_train_seq,\n",
    "        X_val=X_val_seq_scaled,\n",
    "        y_val=y_val_seq,\n",
    "        model_name=\"optimized_lstm\"\n",
    "    )\n",
    "    \n",
    "    # Test optimized model\n",
    "    optimized_test_metrics = optimized_lstm.evaluate(X_test_seq_scaled, y_test_seq)\n",
    "    \n",
    "    print(f\"\\nOptimized LSTM Test Results:\")\n",
    "    print(f\"- Accuracy: {optimized_test_metrics.accuracy:.3f}\")\n",
    "    print(f\"- Precision: {optimized_test_metrics.precision:.3f}\")\n",
    "    print(f\"- Recall: {optimized_test_metrics.recall:.3f}\")\n",
    "    print(f\"- F1 Score: {optimized_test_metrics.f1_score:.3f}\")\n",
    "    print(f\"- AUC-ROC: {optimized_test_metrics.auc_roc:.3f}\")\n",
    "    \n",
    "    # Compare with original\n",
    "    if lstm_model is not None:\n",
    "        print(f\"\\nImprovement over original LSTM:\")\n",
    "        print(f\"- Accuracy: {optimized_test_metrics.accuracy - lstm_test_metrics.accuracy:+.3f}\")\n",
    "        print(f\"- F1 Score: {optimized_test_metrics.f1_score - lstm_test_metrics.f1_score:+.3f}\")\n",
    "        print(f\"- AUC-ROC: {optimized_test_metrics.auc_roc - lstm_test_metrics.auc_roc:+.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available, skipping hyperparameter tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusions and Best Practices\n",
    "\n",
    "Let's summarize our findings and provide recommendations for deep learning in weather prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print(\"Deep Learning for Weather Regulation Prediction - Summary\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if TENSORFLOW_AVAILABLE and 'comparison_df' in locals() and len(comparison_df) > 0:\n",
    "    # Find best overall model\n",
    "    best_f1_idx = comparison_df['F1 Score'].idxmax()\n",
    "    best_model = comparison_df.loc[best_f1_idx, 'Model']\n",
    "    best_f1 = comparison_df.loc[best_f1_idx, 'F1 Score']\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Overall Model: {best_model} (F1: {best_f1:.3f})\")\n",
    "    \n",
    "    # Model-specific insights\n",
    "    print(\"\\nüìä Model-Specific Insights:\")\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        model = row['Model']\n",
    "        if model == 'LSTM':\n",
    "            print(f\"   ‚Ä¢ {model}: Good for sequential patterns, moderate training time\")\n",
    "        elif model == 'Transformer':\n",
    "            print(f\"   ‚Ä¢ {model}: State-of-the-art attention, longer training time\")\n",
    "        elif model == 'Attention-LSTM':\n",
    "            print(f\"   ‚Ä¢ {model}: Combines LSTM memory with attention focus\")\n",
    "        elif model == 'CNN':\n",
    "            print(f\"   ‚Ä¢ {model}: Captures local patterns, fast training\")\n",
    "        elif model == 'Autoencoder':\n",
    "            print(f\"   ‚Ä¢ {model}: Learns compressed representations, good for feature learning\")\n",
    "        elif model == 'Ensemble':\n",
    "            print(f\"   ‚Ä¢ {model}: Combines strengths of multiple models, robust predictions\")\n",
    "    \n",
    "    print(\"\\nüéØ Key Findings:\")\n",
    "    avg_accuracy = comparison_df['Accuracy'].mean()\n",
    "    avg_f1 = comparison_df['F1 Score'].mean()\n",
    "    print(f\"   ‚Ä¢ Average deep learning accuracy: {avg_accuracy:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Average F1 score: {avg_f1:.3f}\")\n",
    "    \n",
    "    fastest_model = comparison_df.loc[comparison_df['Training Time (s)'].idxmin(), 'Model']\n",
    "    slowest_model = comparison_df.loc[comparison_df['Training Time (s)'].idxmax(), 'Model']\n",
    "    print(f\"   ‚Ä¢ Fastest training: {fastest_model}\")\n",
    "    print(f\"   ‚Ä¢ Slowest training: {slowest_model}\")\n",
    "\n",
    "print(\"\\nüî¨ Technical Insights:\")\n",
    "print(\"   ‚Ä¢ Sequential models (LSTM, Transformer) excel at temporal patterns\")\n",
    "print(\"   ‚Ä¢ Attention mechanisms help focus on critical time periods\")\n",
    "print(\"   ‚Ä¢ Ensemble methods provide robust, well-calibrated predictions\")\n",
    "print(\"   ‚Ä¢ CNNs can capture spatial-temporal patterns when data is reshaped\")\n",
    "print(\"   ‚Ä¢ Autoencoders useful for dimensionality reduction and anomaly detection\")\n",
    "\n",
    "print(\"\\n‚ö° Performance Optimization Tips:\")\n",
    "print(\"   ‚Ä¢ Use bidirectional LSTM for better context understanding\")\n",
    "print(\"   ‚Ä¢ Apply dropout (0.2-0.4) to prevent overfitting\")\n",
    "print(\"   ‚Ä¢ Sequence length of 12-48 hours usually optimal for weather\")\n",
    "print(\"   ‚Ä¢ Batch size 32-64 provides good speed/memory trade-off\")\n",
    "print(\"   ‚Ä¢ Early stopping prevents overtraining\")\n",
    "print(\"   ‚Ä¢ Learning rate scheduling improves convergence\")\n",
    "\n",
    "print(\"\\nüéõÔ∏è Hyperparameter Recommendations:\")\n",
    "print(\"   ‚Ä¢ LSTM units: 32-128 (balance complexity vs overfitting)\")\n",
    "print(\"   ‚Ä¢ Transformer heads: 4-8 (match data complexity)\")\n",
    "print(\"   ‚Ä¢ Learning rates: 0.001-0.01 (start conservative)\")\n",
    "print(\"   ‚Ä¢ Use Bayesian optimization for efficient search\")\n",
    "print(\"   ‚Ä¢ Monitor validation metrics to avoid overfitting\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps for Production:\")\n",
    "print(\"   ‚Ä¢ Implement real-time inference pipeline\")\n",
    "print(\"   ‚Ä¢ Add model monitoring and drift detection\")\n",
    "print(\"   ‚Ä¢ Set up automated retraining workflows\")\n",
    "print(\"   ‚Ä¢ Create ensemble of best-performing models\")\n",
    "print(\"   ‚Ä¢ Implement A/B testing for model comparison\")\n",
    "print(\"   ‚Ä¢ Add uncertainty quantification for predictions\")\n",
    "\n",
    "print(\"\\nüìà Future Enhancements:\")\n",
    "print(\"   ‚Ä¢ Multi-modal fusion (weather radar + satellite imagery)\")\n",
    "print(\"   ‚Ä¢ Graph neural networks for airport network effects\")\n",
    "print(\"   ‚Ä¢ Federated learning across multiple airports\")\n",
    "print(\"   ‚Ä¢ Explainable AI for regulatory compliance\")\n",
    "print(\"   ‚Ä¢ Real-time model updates with streaming data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Thank you for exploring deep learning for weather regulation prediction!\")\n",
    "print(\"For more advanced techniques, check out the other tutorial notebooks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Deep Learning with Balanced vs Imbalanced Data\n\nLet's demonstrate the critical importance of balanced datasets for deep learning models by comparing the performance with imbalanced training. This comparison reveals why balanced datasets are essential for aviation regulation prediction.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate impact of balanced vs imbalanced training on deep learning\nif TENSORFLOW_AVAILABLE and use_balanced and lstm_model is not None:\n    print(\"üéØ Deep Learning: Balanced vs Imbalanced Training Comparison\")\n    print(\"=\" * 70)\n    \n    # Create imbalanced training set (simulate real-world 8% regulation rate)\n    n_samples = len(X_train_seq_scaled)\n    regulation_rate = 0.08\n    n_regulations = int(regulation_rate * n_samples)\n    n_no_regulations = n_samples - n_regulations\n    \n    # Get balanced indices\n    reg_indices = np.where(y_train_seq == 1)[0]\n    no_reg_indices = np.where(y_train_seq == 0)[0]\n    \n    # Create imbalanced subset\n    imbalanced_reg_idx = reg_indices[:n_regulations]\n    imbalanced_no_reg_idx = no_reg_indices[:n_no_regulations]\n    imbalanced_indices = np.concatenate([imbalanced_reg_idx, imbalanced_no_reg_idx])\n    \n    X_train_imbalanced = X_train_seq_scaled[imbalanced_indices]\n    y_train_imbalanced = y_train_seq[imbalanced_indices]\n    \n    print(f\"Imbalanced training set:\")\n    print(f\"  ‚Ä¢ Total samples: {len(y_train_imbalanced)}\")\n    print(f\"  ‚Ä¢ Regulations: {y_train_imbalanced.sum()} ({y_train_imbalanced.mean():.1%})\")\n    print(f\"  ‚Ä¢ No regulations: {len(y_train_imbalanced) - y_train_imbalanced.sum()}\")\n    \n    # Train LSTM on imbalanced data\n    print(f\"\\nüîÑ Training LSTM on IMBALANCED dataset...\")\n    lstm_imbalanced_config = LSTMConfig(\n        units=64,\n        dropout=0.3,\n        recurrent_dropout=0.3,\n        bidirectional=True,\n        batch_size=32,\n        epochs=30,\n        sequence_length=sequence_length,\n        learning_rate=0.001,\n        early_stopping_patience=8\n    )\n    \n    lstm_imbalanced = LSTMModel(lstm_imbalanced_config)\n    \n    lstm_imbalanced_results = trainer.train_model(\n        model=lstm_imbalanced,\n        X_train=X_train_imbalanced,\n        y_train=y_train_imbalanced,\n        X_val=X_val_seq_scaled,\n        y_val=y_val_seq,\n        model_name=\"lstm_imbalanced\"\n    )\n    \n    # Evaluate both models on test set\n    lstm_balanced_metrics = lstm_model.evaluate(X_test_seq_scaled, y_test_seq)\n    lstm_imbalanced_metrics = lstm_imbalanced.evaluate(X_test_seq_scaled, y_test_seq)\n    \n    # Comprehensive comparison\n    print(f\"\\nüìä LSTM: Balanced vs Imbalanced Training Results\")\n    print(\"=\" * 80)\n    print(f\"{'Metric':<20} {'Balanced':<15} {'Imbalanced':<15} {'Improvement':<15} {'Relative Gain':<15}\")\n    print(\"-\" * 80)\n    \n    metrics_data = [\n        ('Accuracy', lstm_balanced_metrics.accuracy, lstm_imbalanced_metrics.accuracy),\n        ('Precision', lstm_balanced_metrics.precision, lstm_imbalanced_metrics.precision),\n        ('Recall', lstm_balanced_metrics.recall, lstm_imbalanced_metrics.recall),\n        ('F1 Score', lstm_balanced_metrics.f1_score, lstm_imbalanced_metrics.f1_score),\n        ('AUC-ROC', lstm_balanced_metrics.auc_roc, lstm_imbalanced_metrics.auc_roc)\n    ]\n    \n    improvements = []\n    for metric_name, balanced_val, imbalanced_val in metrics_data:\n        abs_improvement = balanced_val - imbalanced_val\n        rel_improvement = (abs_improvement / imbalanced_val) * 100 if imbalanced_val > 0 else 0\n        improvements.append((metric_name, abs_improvement, rel_improvement))\n        \n        print(f\"{metric_name:<20} {balanced_val:<15.3f} {imbalanced_val:<15.3f} {abs_improvement:<15.3f} {rel_improvement:<14.1f}%\")\n    \n    # Highlight key insights\n    print(f\"\\nüí° Key Deep Learning Insights:\")\n    recall_improvement = next(imp for metric, imp, _ in improvements if metric == 'Recall')[1]\n    f1_improvement = next(imp for metric, imp, _ in improvements if metric == 'F1 Score')[1]\n    \n    print(f\"  ‚Ä¢ Recall improvement: +{recall_improvement:.3f} (Critical for detecting regulations!)\")\n    print(f\"  ‚Ä¢ F1 Score improvement: +{f1_improvement:.3f} (Better overall performance)\")\n    print(f\"  ‚Ä¢ Balanced training helps LSTM learn meaningful sequential patterns\")\n    print(f\"  ‚Ä¢ Neural networks are particularly sensitive to class imbalance\")\n    \n    # Visualize prediction distributions\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    fig.suptitle('Deep Learning: Balanced vs Imbalanced Training Comparison', fontsize=16)\n    \n    # Get predictions\n    balanced_probs = lstm_model.predict_proba(X_test_seq_scaled)[:, 1]\n    imbalanced_probs = lstm_imbalanced.predict_proba(X_test_seq_scaled)[:, 1]\n    \n    # Prediction probability distributions\n    axes[0, 0].hist(balanced_probs[y_test_seq == 0], bins=30, alpha=0.7, label='No Regulation', color='blue')\n    axes[0, 0].hist(balanced_probs[y_test_seq == 1], bins=30, alpha=0.7, label='Regulation', color='red')\n    axes[0, 0].set_title('Balanced LSTM - Prediction Probabilities')\n    axes[0, 0].set_xlabel('Predicted Probability of Regulation')\n    axes[0, 0].set_ylabel('Frequency')\n    axes[0, 0].legend()\n    \n    axes[0, 1].hist(imbalanced_probs[y_test_seq == 0], bins=30, alpha=0.7, label='No Regulation', color='blue')\n    axes[0, 1].hist(imbalanced_probs[y_test_seq == 1], bins=30, alpha=0.7, label='Regulation', color='red')\n    axes[0, 1].set_title('Imbalanced LSTM - Prediction Probabilities')\n    axes[0, 1].set_xlabel('Predicted Probability of Regulation')\n    axes[0, 1].set_ylabel('Frequency')\n    axes[0, 1].legend()\n    \n    # Confusion matrices\n    from sklearn.metrics import confusion_matrix\n    \n    balanced_preds = lstm_model.predict(X_test_seq_scaled)\n    imbalanced_preds = lstm_imbalanced.predict(X_test_seq_scaled)\n    \n    cm_balanced = confusion_matrix(y_test_seq, balanced_preds)\n    cm_imbalanced = confusion_matrix(y_test_seq, imbalanced_preds)\n    \n    sns.heatmap(cm_balanced, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0])\n    axes[1, 0].set_title('Balanced LSTM - Confusion Matrix')\n    axes[1, 0].set_xlabel('Predicted')\n    axes[1, 0].set_ylabel('Actual')\n    \n    sns.heatmap(cm_imbalanced, annot=True, fmt='d', cmap='Reds', ax=axes[1, 1])\n    axes[1, 1].set_title('Imbalanced LSTM - Confusion Matrix')\n    axes[1, 1].set_xlabel('Predicted')\n    axes[1, 1].set_ylabel('Actual')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Learning curve comparison (if training history available)\n    if hasattr(lstm_model, 'training_history') and hasattr(lstm_imbalanced, 'training_history'):\n        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n        \n        # Loss comparison\n        if lstm_model.training_history and 'loss' in lstm_model.training_history:\n            axes[0].plot(lstm_model.training_history['loss'], label='Balanced Training Loss', color='blue')\n            axes[0].plot(lstm_model.training_history.get('val_loss', []), label='Balanced Validation Loss', color='lightblue')\n        \n        if lstm_imbalanced.training_history and 'loss' in lstm_imbalanced.training_history:\n            axes[0].plot(lstm_imbalanced.training_history['loss'], label='Imbalanced Training Loss', color='red')\n            axes[0].plot(lstm_imbalanced.training_history.get('val_loss', []), label='Imbalanced Validation Loss', color='lightcoral')\n        \n        axes[0].set_title('Training Loss Comparison')\n        axes[0].set_xlabel('Epoch')\n        axes[0].set_ylabel('Loss')\n        axes[0].legend()\n        axes[0].grid(True, alpha=0.3)\n        \n        # Accuracy comparison\n        if lstm_model.training_history and 'accuracy' in lstm_model.training_history:\n            axes[1].plot(lstm_model.training_history['accuracy'], label='Balanced Training Accuracy', color='blue')\n            axes[1].plot(lstm_model.training_history.get('val_accuracy', []), label='Balanced Validation Accuracy', color='lightblue')\n        \n        if lstm_imbalanced.training_history and 'accuracy' in lstm_imbalanced.training_history:\n            axes[1].plot(lstm_imbalanced.training_history['accuracy'], label='Imbalanced Training Accuracy', color='red')\n            axes[1].plot(lstm_imbalanced.training_history.get('val_accuracy', []), label='Imbalanced Validation Accuracy', color='lightcoral')\n        \n        axes[1].set_title('Training Accuracy Comparison')\n        axes[1].set_xlabel('Epoch')\n        axes[1].set_ylabel('Accuracy')\n        axes[1].legend()\n        axes[1].grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()\n    \n    print(f\"\\nüéØ Conclusion:\")\n    print(f\"Balanced datasets are CRITICAL for deep learning in aviation regulation prediction:\")\n    print(f\"‚Ä¢ Enable better detection of rare but important regulation events\")\n    print(f\"‚Ä¢ Improve gradient flow and feature learning in neural networks\") \n    print(f\"‚Ä¢ Provide more reliable and calibrated probability predictions\")\n    print(f\"‚Ä¢ Essential for operational deployment where missing regulations is costly\")\n    \nelif not use_balanced:\n    print(\"This demonstration requires the balanced dataset.\")\n    print(\"The benefits of balanced training for deep learning include:\")\n    print(\"‚Ä¢ Better gradient flow during backpropagation\")\n    print(\"‚Ä¢ Improved feature learning for both classes\")\n    print(\"‚Ä¢ More reliable probability calibration\")\n    print(\"‚Ä¢ Enhanced pattern recognition capabilities\")\n    \nelif not TENSORFLOW_AVAILABLE:\n    print(\"TensorFlow is required for this deep learning comparison.\")\n    \nelse:\n    print(\"LSTM model training is required for this comparison.\")",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}